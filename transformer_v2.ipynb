{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections.abc import Callable\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from utilities import (\n",
    "    Embedding,\n",
    "    LayerNorm,\n",
    "    Dropout,\n",
    "    Linear,\n",
    "    DictReLU,\n",
    "    pbt_init,\n",
    "    pbt_update,\n",
    "    Optimizer,\n",
    "    get_dataloader_random_reshuffle,\n",
    "    evaluate_model,\n",
    "    update_model,\n",
    "    get_array_minibatch,\n",
    "    get_accuracy,\n",
    "    AdamW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"device\": \"mps\",\n",
    "    \"ensemble_shape\": (1,),\n",
    "    \"float_dtype\": torch.float32,\n",
    "    \"hyperparameter_raw_init_distributions\": {\n",
    "        \"dropout_p\": torch.distributions.Uniform(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(.01, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"epsilon\": torch.distributions.Uniform(\n",
    "            torch.tensor(-10, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(-5, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"first_moment_decay\": torch.distributions.Uniform(\n",
    "            torch.tensor(-3, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"learning_rate\": torch.distributions.Uniform(\n",
    "            torch.tensor(-5, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(-1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"second_moment_decay\": torch.distributions.Uniform(\n",
    "            torch.tensor(-5, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(-1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"weight_decay\": torch.distributions.Uniform(\n",
    "            torch.tensor(-5, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(-1, device=\"mps\", dtype=torch.float32)\n",
    "        )\n",
    "    },\n",
    "    \"hyperparameter_raw_perturb\": {\n",
    "        \"dropout_p\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(.01, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"epsilon\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"first_moment_decay\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"learning_rate\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"second_moment_decay\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"weight_decay\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"mps\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"mps\", dtype=torch.float32)\n",
    "        ),\n",
    "    },\n",
    "    \"hyperparameter_transforms\": {\n",
    "        \"dropout_p\": lambda p: p.clip(0,1),\n",
    "        \"epsilon\": lambda log10: 10 ** log10,\n",
    "        \"first_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
    "        \"learning_rate\": lambda log10: 10 ** log10,\n",
    "        \"second_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
    "        \"weight_decay\": lambda log10: 10 ** log10,\n",
    "    },\n",
    "    \"improvement_threshold\": 1e-4,\n",
    "    \"minibatch_size\": 100,\n",
    "    \"pbt\": True,\n",
    "    \"seed\": 1,\n",
    "    \"sequence_size\": 64,\n",
    "    \"steps_num\": 10000,\n",
    "    \"steps_without_improvement\": 1_000,\n",
    "    \"valid_interval\": 100,\n",
    "    \"welch_confidence_level\": .95,\n",
    "    \"welch_sample_size\": 1024,\n",
    "    \"embedding_dim\": 36,\n",
    "    \"dropout_p\": torch.tensor([1], device='mps'),\n",
    "    \"n_heads\": 3,\n",
    "    \"block_num\": 2,\n",
    "    \"minibatch_size_eval\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11fc52ef0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 36])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_positional_embeddings(sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d, device=config[\"device\"])\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result\n",
    "\n",
    "pos_embed = get_positional_embeddings(64, config[\"embedding_dim\"])[None, :]\n",
    "pos_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        embedding_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.piece_embed = Embedding(config, embedding_dim, vocabulary_size=6)\n",
    "        self.player_embed = Embedding(config, embedding_dim, vocabulary_size=2)\n",
    "        self.dropout = Dropout(config)\n",
    "        self.pos_embed = pos_embed\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input[0]\n",
    "        embedded_pieces = self.dropout({'features': self.piece_embed(input[...,0])})\n",
    "        embedded_players = self.dropout({'features': self.player_embed(input[...,1])})\n",
    "        embedded_pos = self.pos_embed\n",
    "        \n",
    "        output = embedded_pieces['features'] + embedded_players['features'] + embedded_pos\n",
    "        \n",
    "        return {'features': output.to(config[\"device\"]), 'mask': torch.ones((config['minibatch_size'], config['sequence_size']), device=config['device']).to(torch.bool)}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Pre-LN multi-head self-attention block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attention_head_num : `int`\n",
    "        The number of attention heads.\n",
    "    config : `int`\n",
    "        Configuration dictionary. Required key-value pairs:\n",
    "        `\"device\"` : `str`\n",
    "            The device to store parameters on.\n",
    "        `\"dropout_p\"` : `torch.Tensor`\n",
    "            Dropout probability tensor, of shape `ensemble_shape`.\n",
    "        `\"ensemble_shape\"` : `tuple[int]`\n",
    "            Ensemble shape.      \n",
    "        `\"float_dtype\"` : `torch.dtype`\n",
    "            The floating point datatype to use for the parameters.\n",
    "    embedding_dim : `int`\n",
    "        The feature dimension of internal representations.\n",
    "\n",
    "    Calling\n",
    "    -------\n",
    "    Instance calls require one positional argument:\n",
    "    batch : `dict`\n",
    "        The input data dictionary. Required keys:\n",
    "        `\"features\"` : `torch.Tensor`\n",
    "            Tensor of element-level features, of shape\n",
    "            `batch_shape + (sequence_dim, embedding_dim)` or\n",
    "            `ensemble_shape + batch_shape + (sequence_dim, embedding_dim)`\n",
    "        `\"mask\"` : `torch.Tensor`\n",
    "            Mask showing which entries are not padding, of shape\n",
    "            `batch_shape + (sequence_dim,)` or\n",
    "            `ensemble_shape + batch_shape + (sequence_dim,)`\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_head_num: int,\n",
    "        config: dict,\n",
    "        embedding_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_head_num = attention_head_num\n",
    "        self.config = config\n",
    "        self.dropout = Dropout(config)\n",
    "        self.layer_norm = LayerNorm(\n",
    "            config,\n",
    "            embedding_dim\n",
    "        )\n",
    "\n",
    "        (\n",
    "            self.key_weights,\n",
    "            self.output_weights,\n",
    "            self.query_weights,\n",
    "            self.value_weights\n",
    "        ) = (\n",
    "            Linear(\n",
    "                config,\n",
    "                embedding_dim,\n",
    "                embedding_dim,\n",
    "                bias=False\n",
    "            )\n",
    "            for _ in range(4)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: dict\n",
    "    ) -> dict:\n",
    "        skip = batch[\"features\"]\n",
    "        batch = self.layer_norm(batch)\n",
    "        residual, mask = (batch[key] for key in (\"features\", \"mask\"))\n",
    "\n",
    "        sequence_dim, embedding_dim = residual.shape[-2:]\n",
    "        key_dim = embedding_dim // self.attention_head_num\n",
    "\n",
    "        key, query, value = (\n",
    "            (\n",
    "                linear(residual)\n",
    "            ).reshape(\n",
    "                residual.shape[:-1] + (self.attention_head_num, key_dim)\n",
    "            ).transpose(-3, -2)\n",
    "            for linear in (\n",
    "                self.key_weights,\n",
    "                self.query_weights,\n",
    "                self.value_weights\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        arange = torch.arange(sequence_dim, device=mask.device)\n",
    "        attention_mask = mask[..., None, :] & mask[..., None]\n",
    "        attention_mask |= (arange == arange[:, None])\n",
    "\n",
    "        pooled_values = F.scaled_dot_product_attention(\n",
    "            query,\n",
    "            key,\n",
    "            value,\n",
    "            attention_mask[..., None, :, :]\n",
    "        )\n",
    "\n",
    "        residual = pooled_values.transpose(-3, -2).reshape(residual.shape)\n",
    "        residual = self.output_weights(residual)\n",
    "        residual = self.dropout({\"features\": residual})[\"features\"]\n",
    "\n",
    "        features = skip + residual\n",
    "\n",
    "        return batch | {\"features\": features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pre-LN feedforward block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : `int`\n",
    "        Configuration dictionary. Required key-value pairs:\n",
    "        `\"device\"` : `str`\n",
    "            The device to store parameters on.\n",
    "        `\"dropout_p\"` : `torch.Tensor`\n",
    "            Dropout probability tensor, of shape `ensemble_shape`.\n",
    "        `\"ensemble_shape\"` : `tuple[int]`\n",
    "            Ensemble shape.      \n",
    "        `\"float_dtype\"` : `torch.dtype`\n",
    "            The floating point datatype to use for the parameters.\n",
    "    embedding_dim : `int`\n",
    "        The feature dimension of internal representations.\n",
    "\n",
    "    Calling\n",
    "    -------\n",
    "    Instance calls require one positional argument:\n",
    "    batch : `dict`\n",
    "        The input data dictionary. Required key:\n",
    "        `\"features\"` : `torch.Tensor`\n",
    "            Tensor of element-level features, of shape\n",
    "            `batch_shape + (sequence_dim, embedding_dim)` or\n",
    "            `ensemble_shape + batch_shape + (sequence_dim, embedding_dim)`\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        embedding_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_f = torch.nn.Sequential(\n",
    "            LayerNorm(\n",
    "                config,\n",
    "                embedding_dim\n",
    "            ),\n",
    "            Linear(\n",
    "                config,\n",
    "                embedding_dim,\n",
    "                embedding_dim,\n",
    "                init_multiplier=2 ** .5\n",
    "            ),\n",
    "            DictReLU(),\n",
    "            Linear(\n",
    "                config,\n",
    "                embedding_dim,\n",
    "                embedding_dim\n",
    "            ),\n",
    "            Dropout(config)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, batch: dict) -> dict:\n",
    "        skip = batch\n",
    "\n",
    "        residual = self.residual_f(batch)\n",
    "\n",
    "        features = skip[\"features\"] + residual[\"features\"]\n",
    "\n",
    "        return batch | {\"features\": features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(\n",
    "    config: dict,\n",
    "    dataset_train: dict,\n",
    "    dataset_valid: dict,\n",
    "    get_loss: Callable[[dict, torch.Tensor], torch.Tensor],\n",
    "    get_metric: Callable[[dict, torch.Tensor], torch.Tensor],\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "    target_key=\"target\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Population-based training on a supervised learning task.\n",
    "    Tuned hyperparameters are given by raw values and transformations.\n",
    "    This way, the hyperparameters are perturbed by\n",
    "    additive noise on raw values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : `dict`\n",
    "        Configuration dictionary. Required key-value pairs:\n",
    "        `\"ensemble_shape\"` : tuple[int]\n",
    "            Ensemble shape. We assume this is a 1-dimensional tuple\n",
    "            with dimensions the population size.\n",
    "        `\"hyperparameter_raw_init_distributions\"` : `dict`\n",
    "            Dictionary that maps tuned hyperparameter names\n",
    "            to `torch.distributions.Distribution` of raw hyperparameter values.\n",
    "            Required keys:\n",
    "            `\"learning_rate\"`:\n",
    "                The learning rate of stochastic gradient descent.\n",
    "        `\"hyperparameter_raw_perturbs\"` : `dict`\n",
    "            Dictionary that maps tuned hyperparameter names\n",
    "            to `torch.distributions.Distribution` of additive noise.\n",
    "        `\"hyperparameter_transforms\"` : `dict`\n",
    "            Dictionary that maps tuned hyperparameter names\n",
    "            to transformations of raw hyperparameter values.\n",
    "        `\"improvement_threshold\"` : `float`\n",
    "            A new metric score has to be this much better\n",
    "            than the previous best to count as an improvement.\n",
    "        `\"minibatch_size\"` : `int`\n",
    "            Minibatch size to use in a training step.\n",
    "        `\"minibatch_size_eval\"` : `int`\n",
    "            Minibatch size to use in evaluation.\n",
    "            On CPU, should be about the same as `minibatch_size`.\n",
    "            On GPU, should be as big as possible without\n",
    "            incurring an Out of Memory error.\n",
    "        `\"pbt\"` : `bool`\n",
    "            Whether to use PBT updates in validations.\n",
    "            If `False`, the algorithm just samples hyperparameters at start,\n",
    "            then keeps them constant.\n",
    "        `\"steps_num\"` : `int`\n",
    "            Maximum number of training steps.\n",
    "        `\"steps_without_improvement`\" : `int`\n",
    "            If the number of training steps without improvement\n",
    "            exceeds this value, then training is stopped.\n",
    "        `\"valid_interval\"` : `int`\n",
    "            Frequency of evaluations, measured in number of training steps.\n",
    "        `\"welch_confidence_level\"` : `float`\n",
    "            The confidence level in Welch's t-test\n",
    "            that is used in determining if a population member\n",
    "            is to be replaced by another member with perturbed hyperparameters.\n",
    "        `\"welch_sample_size\"` : `int`\n",
    "            The last this many validation metrics are used\n",
    "            in Welch's t-test.\n",
    "    dataset_train : `dict`\n",
    "        The dataset to train the model on.\n",
    "    dataset_valid : `dict`\n",
    "        The dataset to evaluate the model on.\n",
    "    `get_loss` : `Callable[[dict, torch.Tensor], torch.Tensor]`\n",
    "        A function that maps a pair of model output and target value tensor\n",
    "        to a tensor of losses per ensemble member.\n",
    "    `get_metric` : `Callable[[dict, torch.Tensor], torch.Tensor]`\n",
    "        A function that maps a pair of model output and target value tensor\n",
    "        to a tensor of metrics per ensemble member.\n",
    "        We assume a greater metric is better.\n",
    "    `model` : `torch.nn.Module`\n",
    "        The model ensemble to tune.\n",
    "    `optimizer` : `Optimizer`\n",
    "        An optimizer that tracks the parameters of `model`.\n",
    "    indptr_key : `str`, optional\n",
    "        If the dataset has sequential entries,\n",
    "        then this is the key of the index pointer tensor.\n",
    "        Default: `\"indptr\"`.\n",
    "    target_key : `str`, optional\n",
    "        The key mapped to the target value tensor in the dataset.\n",
    "        Default: `\"target\"`\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    An output dictionary with the following key-value pairs:\n",
    "        `\"source mask\"` : `torch.Tensor`\n",
    "            The source masks of population members\n",
    "            that were replace by other members in a PBT update\n",
    "        `\"target indices\"` : `torch.Tensor`\n",
    "            The indices of population members\n",
    "            that the member where the source mask is to were replaced with.\n",
    "        `\"validation metric\"` : `torch.Tensor`\n",
    "            The validation metrics at evaluation steps.\n",
    "\n",
    "        In addition, for each tuned hyperparameter name,\n",
    "        we include a `torch.Tensor` of values per update.\n",
    "    \"\"\"\n",
    "    ensemble_shape = config[\"ensemble_shape\"]\n",
    "    if len(ensemble_shape) != 1:\n",
    "        raise ValueError(f\"The number of dimensions in the ensemble shape should be 1 for the  population size, but it is {len(ensemble_shape)}\")\n",
    "\n",
    "    config_local = dict(config)\n",
    "    log = defaultdict(list)\n",
    "\n",
    "    pbt_init(config_local, log)\n",
    "\n",
    "    update_model(config_local, model)\n",
    "    optimizer.update_config(config_local)\n",
    "\n",
    "    best_valid_metric = -torch.inf\n",
    "    progress_bar = tqdm.trange(config[\"steps_num\"])\n",
    "    steps_without_improvement = 0\n",
    "    train_dataloader = get_dataloader_random_reshuffle(\n",
    "        config,\n",
    "        dataset_train[\"features\"],\n",
    "        dataset_train[\"labels\"]\n",
    "    )\n",
    "\n",
    "    for step_id in progress_bar:\n",
    "        model.train()\n",
    "        minibatch = next(train_dataloader)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predict = model(minibatch[0])[0][...,0]\n",
    "        target = minibatch[1][0]\n",
    "\n",
    "        loss = get_loss(predict, target).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step_id % config[\"valid_interval\"] == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                split_name = \"validation\"\n",
    "                minibatch = next(train_dataloader)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predict = model(minibatch[0])[0][...,0]\n",
    "                target = minibatch[1][0]\n",
    "                \n",
    "                print(predict.argmax(dim=-1))\n",
    "                print(target)\n",
    "                \n",
    "                metric = (predict.argmax(dim=-1) == target).to(config[\"float_dtype\"]).mean()\n",
    "                \n",
    "                # log[f\"{split_name} loss\"].append(loss)\n",
    "                log[f\"{split_name} metric\"].append(metric)\n",
    "                # print(\n",
    "                #     f\"{split_name} loss {loss.min().cpu().item():.4f}\"\n",
    "                # )\n",
    "                print(\n",
    "                    f\"{split_name} metric {metric.max().cpu().item():.4f}\"\n",
    "                )\n",
    "\n",
    "                best_last_metric = log[\"validation metric\"][-1].max()\n",
    "                print(\n",
    "                    f\"Best last metric {best_last_metric.cpu().item():.2f}\",\n",
    "                    flush=True\n",
    "                )\n",
    "                if (\n",
    "                    best_valid_metric + config[\"improvement_threshold\"]\n",
    "                ) < best_last_metric:\n",
    "                    print(\n",
    "                        f\"New best metric\",\n",
    "                        flush=True\n",
    "                    )\n",
    "                    best_valid_metric = best_last_metric\n",
    "                    steps_without_improvement = 0\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Best metric {best_valid_metric.cpu().item():.2f}\",\n",
    "                        flush=True\n",
    "                    )\n",
    "                    steps_without_improvement += config[\"valid_interval\"]\n",
    "                    if steps_without_improvement > config[\n",
    "                        \"steps_without_improvement\"\n",
    "                    ]:\n",
    "                        break\n",
    "\n",
    "                if config[\"pbt\"] and (len(log[\"validation metric\"]) >= config[\n",
    "                    \"welch_sample_size\"\n",
    "                ]):\n",
    "                    evaluations = torch.stack(\n",
    "                        log[\"validation metric\"][-config[\"welch_sample_size\"]:]\n",
    "                    )\n",
    "                    pbt_update(\n",
    "                        config_local, evaluations, log, optimizer.get_parameters()\n",
    "                    )\n",
    "\n",
    "                    update_model(config_local, model)\n",
    "                    optimizer.update_config(config_local)\n",
    "\n",
    "\n",
    "    progress_bar.close()\n",
    "    for key, value in log.items():\n",
    "        if isinstance(value, list):\n",
    "            log[key] = torch.stack(value)\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        embedding_dim = config[\"embedding_dim\"]\n",
    "        n_heads = config[\"n_heads\"]\n",
    "        block_num = config[\"block_num\"]\n",
    "        \n",
    "        # create embedding block\n",
    "        self.EmbeddingBlock = EmbeddingBlock(config, embedding_dim)\n",
    "        \n",
    "        # make repeated transformer block\n",
    "        blocks = []\n",
    "        for _ in range(block_num):\n",
    "            blocks.extend([\n",
    "                MultiHeadSelfAttentionBlock(n_heads, config, embedding_dim),\n",
    "                FeedForwardBlock(config, embedding_dim)\n",
    "            ])\n",
    "        self.MHA_FF_Block = nn.Sequential(*blocks)\n",
    "        \n",
    "        # use Linear to create logits\n",
    "        self.Linear = Linear(config, embedding_dim, 1)\n",
    "        \n",
    "        # use softmax\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded_inputs = self.EmbeddingBlock(input)\n",
    "        \n",
    "        out = self.MHA_FF_Block(embedded_inputs)\n",
    "        \n",
    "        logits = self.Linear(out)[\"features\"]\n",
    "        \n",
    "        logits = self.softmax(logits)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('data/dataset_v2.pt')\n",
    "dataset_train, dataset_valid = {}, {}\n",
    "dataset_train[\"features\"], dataset_valid[\"features\"], dataset_train[\"labels\"], dataset_valid[\"labels\"] = train_test_split(\n",
    "    dataset[\"features\"], dataset[\"labels\"][:,0], test_size=0.2, random_state=config['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14, 54, 54, 41, 54, 47, 40, 31, 38, 52, 38, 28, 53, 21, 47, 21,  8, 47,\n",
      "        38, 48, 31, 38, 38, 39, 52, 54, 54, 21, 31, 38, 21, 38, 54, 38, 21, 21,\n",
      "        49, 40, 46, 52, 54, 47, 21, 33, 38, 54, 38, 38, 54, 54, 54, 54, 46, 14,\n",
      "        25, 38, 40, 47, 52, 54, 35, 43, 21, 46, 38, 55, 43, 47, 38, 40, 46, 39,\n",
      "        22, 40, 46, 38, 54, 38, 53, 43, 55, 40, 21, 39, 38, 47, 40, 38, 38, 22,\n",
      "        38, 54, 40, 46, 38, 40, 47, 47, 46, 46], device='mps:0')\n",
      "tensor([16, 59, 26, 21, 47, 14, 58, 46, 56, 26, 58, 25, 14, 36,  6, 55, 28,  0,\n",
      "        61,  3, 54, 61, 50, 57, 47, 36, 10, 32, 39, 52, 28, 29,  2, 58, 45, 30,\n",
      "        22, 21,  5, 15, 56,  1, 14, 30, 29, 17, 52, 52,  4, 39, 11, 13, 11,  5,\n",
      "         6, 55, 18,  8, 10, 15, 11, 39, 59,  2, 54, 12, 49,  5, 37,  1, 38, 35,\n",
      "        12, 43,  5, 34, 62, 62, 44, 56, 33,  2, 28, 55, 27, 25, 44, 54, 46,  8,\n",
      "        61, 34, 23, 12, 36,  6, 18, 22, 26, 23], device='mps:0')\n",
      "validation metric 0.0000\n",
      "Best last metric 0.00\n",
      "New best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/10000 [00:37<1:01:15,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47,  6, 57,  1, 52, 52, 30, 16, 49, 33, 61, 57, 42, 24, 49, 20, 35, 37,\n",
      "        36, 22, 57, 43, 40,  9, 12,  9, 53, 42, 29, 46, 51, 59, 34, 21, 57, 23,\n",
      "        22, 10, 45, 52, 49, 28, 62, 26, 41,  6, 39, 10, 54, 31, 42, 15, 48, 46,\n",
      "        57, 42, 48, 27, 63, 44, 56, 12,  1, 13,  6, 53,  9, 58, 57, 39, 21, 60,\n",
      "         4, 53, 62, 32, 21, 11,  2,  2,  8, 59, 18, 42, 21, 19, 35, 57,  6,  6,\n",
      "         3, 42, 11,  0,  1,  7,  2, 26,  6, 12], device='mps:0')\n",
      "tensor([33, 11, 25,  2, 42,  7, 30, 24, 56, 10, 60, 39, 42, 24, 49, 43,  8, 20,\n",
      "        30, 58, 61, 43, 62, 11,  4, 11, 53, 35, 29, 35, 49, 34, 33, 10, 51, 19,\n",
      "         4, 10, 25, 33, 49,  6, 11, 58, 24,  1, 26,  9, 59, 10, 15, 15, 61, 22,\n",
      "        50, 38, 48, 20, 63, 46, 35, 19,  1, 29, 22, 32,  3, 50, 62,  9, 31, 60,\n",
      "        50, 53, 48, 55, 11, 52,  2, 30, 57, 61, 14, 58, 20, 60, 35, 60,  6, 11,\n",
      "        24, 34,  5,  0,  4, 29,  8, 44,  6,  2], device='mps:0')\n",
      "validation metric 0.2000\n",
      "Best last metric 0.20\n",
      "New best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 113/10000 [00:42<1:02:16,  2.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[220], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Transformer(config)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m----> 4\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_supervised\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_accuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[217], line 133\u001b[0m, in \u001b[0;36mtrain_supervised\u001b[0;34m(config, dataset_train, dataset_valid, get_loss, get_metric, model, optimizer, target_key)\u001b[0m\n\u001b[1;32m    129\u001b[0m target \u001b[38;5;241m=\u001b[39m minibatch[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    131\u001b[0m loss \u001b[38;5;241m=\u001b[39m get_loss(predict, target)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m--> 133\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step_id \u001b[38;5;241m%\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/deep_learning/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep_learning/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep_learning/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = Transformer(config)\n",
    "optimizer = AdamW(model.parameters())\n",
    "\n",
    "log = train_supervised(\n",
    "    config,\n",
    "    dataset_train,\n",
    "    dataset_valid,\n",
    "    CrossEntropyLoss(),\n",
    "    get_accuracy,\n",
    "    model,\n",
    "    optimizer,\n",
    "    target_key=\"labels\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
