{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections.abc import Callable\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from utilities import (\n",
    "    Embedding,\n",
    "    LayerNorm,\n",
    "    Dropout,\n",
    "    Linear,\n",
    "    DictReLU,\n",
    "    pbt_init,\n",
    "    pbt_update,\n",
    "    Optimizer,\n",
    "    get_dataloader_random_reshuffle,\n",
    "    evaluate_model,\n",
    "    update_model,\n",
    "    get_array_minibatch,\n",
    "    get_accuracy,\n",
    "    AdamW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"device\": \"cuda\",\n",
    "    \"ensemble_shape\": (1,),\n",
    "    \"float_dtype\": torch.float32,\n",
    "    \"hyperparameter_raw_init_distributions\": {\n",
    "        \"dropout_p\": torch.distributions.Uniform(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(.01, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"epsilon\": torch.distributions.Uniform(\n",
    "            torch.tensor(-10, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(-5, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"first_moment_decay\": torch.distributions.Uniform(\n",
    "            torch.tensor(-3, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"learning_rate\": torch.distributions.Uniform(\n",
    "            torch.tensor(-5, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(-1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"second_moment_decay\": torch.distributions.Uniform(\n",
    "            torch.tensor(-5, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(-1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"weight_decay\": torch.distributions.Uniform(\n",
    "            torch.tensor(-5, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(-1, device=\"cuda\", dtype=torch.float32)\n",
    "        )\n",
    "    },\n",
    "    \"hyperparameter_raw_perturb\": {\n",
    "        \"dropout_p\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(.01, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"epsilon\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"first_moment_decay\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"learning_rate\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"second_moment_decay\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "        \"weight_decay\": torch.distributions.Normal(\n",
    "            torch.tensor(0, device=\"cuda\", dtype=torch.float32),\n",
    "            torch.tensor(1, device=\"cuda\", dtype=torch.float32)\n",
    "        ),\n",
    "    },\n",
    "    \"hyperparameter_transforms\": {\n",
    "        \"dropout_p\": lambda p: p.clip(0,1),\n",
    "        \"epsilon\": lambda log10: 10 ** log10,\n",
    "        \"first_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
    "        \"learning_rate\": lambda log10: 10 ** log10,\n",
    "        \"second_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
    "        \"weight_decay\": lambda log10: 10 ** log10,\n",
    "    },\n",
    "    \"improvement_threshold\": 1e-4,\n",
    "    \"minibatch_size\": 100,\n",
    "    \"pbt\": True,\n",
    "    \"seed\": 1,\n",
    "    \"sequence_size\": 64,\n",
    "    \"steps_num\": 10000,\n",
    "    \"steps_without_improvement\": 5_000,\n",
    "    \"valid_interval\": 500,\n",
    "    \"welch_confidence_level\": .95,\n",
    "    \"welch_sample_size\": 1024,\n",
    "    \"embedding_dim\": 144,\n",
    "    \"dropout_p\": torch.tensor([.1], device='cuda'),\n",
    "    \"n_heads\": 3,\n",
    "    \"block_num\": 1,\n",
    "    \"minibatch_size_eval\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x9dea010>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d, device=config[\"device\"])\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result\n",
    "\n",
    "pos_embed = get_positional_embeddings(64, config[\"embedding_dim\"])[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        embedding_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.piece_embed = Embedding(config, embedding_dim, vocabulary_size=7)\n",
    "        self.player_embed = Embedding(config, embedding_dim, vocabulary_size=2)\n",
    "        self.dropout = Dropout(config)\n",
    "        self.pos_embed = pos_embed\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input[0]\n",
    "        embedded_pieces = self.dropout({'features': self.piece_embed(input[...,0])})\n",
    "        embedded_players = self.dropout({'features': self.player_embed(input[...,1])})\n",
    "        embedded_pos = self.pos_embed\n",
    "        \n",
    "        output = embedded_pieces['features'] + embedded_players['features'] + embedded_pos\n",
    "        \n",
    "        return {'features': output.to(config[\"device\"]), 'mask': torch.ones((config['minibatch_size'], config['sequence_size']), device=config['device']).to(torch.bool)}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Pre-LN multi-head self-attention block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attention_head_num : `int`\n",
    "        The number of attention heads.\n",
    "    config : `int`\n",
    "        Configuration dictionary. Required key-value pairs:\n",
    "        `\"device\"` : `str`\n",
    "            The device to store parameters on.\n",
    "        `\"dropout_p\"` : `torch.Tensor`\n",
    "            Dropout probability tensor, of shape `ensemble_shape`.\n",
    "        `\"ensemble_shape\"` : `tuple[int]`\n",
    "            Ensemble shape.      \n",
    "        `\"float_dtype\"` : `torch.dtype`\n",
    "            The floating point datatype to use for the parameters.\n",
    "    embedding_dim : `int`\n",
    "        The feature dimension of internal representations.\n",
    "\n",
    "    Calling\n",
    "    -------\n",
    "    Instance calls require one positional argument:\n",
    "    batch : `dict`\n",
    "        The input data dictionary. Required keys:\n",
    "        `\"features\"` : `torch.Tensor`\n",
    "            Tensor of element-level features, of shape\n",
    "            `batch_shape + (sequence_dim, embedding_dim)` or\n",
    "            `ensemble_shape + batch_shape + (sequence_dim, embedding_dim)`\n",
    "        `\"mask\"` : `torch.Tensor`\n",
    "            Mask showing which entries are not padding, of shape\n",
    "            `batch_shape + (sequence_dim,)` or\n",
    "            `ensemble_shape + batch_shape + (sequence_dim,)`\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_head_num: int,\n",
    "        config: dict,\n",
    "        embedding_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_head_num = attention_head_num\n",
    "        self.config = config\n",
    "        self.dropout = Dropout(config)\n",
    "        self.layer_norm = LayerNorm(\n",
    "            config,\n",
    "            embedding_dim\n",
    "        )\n",
    "\n",
    "        (\n",
    "            self.key_weights,\n",
    "            self.output_weights,\n",
    "            self.query_weights,\n",
    "            self.value_weights\n",
    "        ) = (\n",
    "            Linear(\n",
    "                config,\n",
    "                embedding_dim,\n",
    "                embedding_dim,\n",
    "                bias=False\n",
    "            )\n",
    "            for _ in range(4)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: dict\n",
    "    ) -> dict:\n",
    "        skip = batch[\"features\"]\n",
    "        batch = self.layer_norm(batch)\n",
    "        residual, mask = (batch[key] for key in (\"features\", \"mask\"))\n",
    "\n",
    "        sequence_dim, embedding_dim = residual.shape[-2:]\n",
    "        key_dim = embedding_dim // self.attention_head_num\n",
    "\n",
    "        key, query, value = (\n",
    "            (\n",
    "                linear(residual)\n",
    "            ).reshape(\n",
    "                residual.shape[:-1] + (self.attention_head_num, key_dim)\n",
    "            ).transpose(-3, -2)\n",
    "            for linear in (\n",
    "                self.key_weights,\n",
    "                self.query_weights,\n",
    "                self.value_weights\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        arange = torch.arange(sequence_dim, device=mask.device)\n",
    "        attention_mask = mask[..., None, :] & mask[..., None]\n",
    "        attention_mask |= (arange == arange[:, None])\n",
    "\n",
    "        pooled_values = F.scaled_dot_product_attention(\n",
    "            query,\n",
    "            key,\n",
    "            value,\n",
    "            attention_mask[..., None, :, :]\n",
    "        )\n",
    "\n",
    "        residual = pooled_values.transpose(-3, -2).reshape(residual.shape)\n",
    "        residual = self.output_weights(residual)\n",
    "        residual = self.dropout({\"features\": residual})[\"features\"]\n",
    "\n",
    "        features = skip + residual\n",
    "\n",
    "        return batch | {\"features\": features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pre-LN feedforward block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : `int`\n",
    "        Configuration dictionary. Required key-value pairs:\n",
    "        `\"device\"` : `str`\n",
    "            The device to store parameters on.\n",
    "        `\"dropout_p\"` : `torch.Tensor`\n",
    "            Dropout probability tensor, of shape `ensemble_shape`.\n",
    "        `\"ensemble_shape\"` : `tuple[int]`\n",
    "            Ensemble shape.      \n",
    "        `\"float_dtype\"` : `torch.dtype`\n",
    "            The floating point datatype to use for the parameters.\n",
    "    embedding_dim : `int`\n",
    "        The feature dimension of internal representations.\n",
    "\n",
    "    Calling\n",
    "    -------\n",
    "    Instance calls require one positional argument:\n",
    "    batch : `dict`\n",
    "        The input data dictionary. Required key:\n",
    "        `\"features\"` : `torch.Tensor`\n",
    "            Tensor of element-level features, of shape\n",
    "            `batch_shape + (sequence_dim, embedding_dim)` or\n",
    "            `ensemble_shape + batch_shape + (sequence_dim, embedding_dim)`\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "        embedding_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_f = torch.nn.Sequential(\n",
    "            LayerNorm(\n",
    "                config,\n",
    "                embedding_dim\n",
    "            ),\n",
    "            Linear(\n",
    "                config,\n",
    "                embedding_dim,\n",
    "                embedding_dim,\n",
    "                init_multiplier=2 ** .5\n",
    "            ),\n",
    "            DictReLU(),\n",
    "            Linear(\n",
    "                config,\n",
    "                embedding_dim,\n",
    "                embedding_dim\n",
    "            ),\n",
    "            Dropout(config)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, batch: dict) -> dict:\n",
    "        skip = batch\n",
    "\n",
    "        residual = self.residual_f(batch)\n",
    "\n",
    "        features = skip[\"features\"] + residual[\"features\"]\n",
    "\n",
    "        return batch | {\"features\": features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(\n",
    "    config: dict,\n",
    "    dataset_train: dict,\n",
    "    dataset_valid: dict,\n",
    "    get_loss: Callable[[dict, torch.Tensor], torch.Tensor],\n",
    "    get_metric: Callable[[dict, torch.Tensor], torch.Tensor],\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "    target_key=\"target\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Population-based training on a supervised learning task.\n",
    "    Tuned hyperparameters are given by raw values and transformations.\n",
    "    This way, the hyperparameters are perturbed by\n",
    "    additive noise on raw values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : `dict`\n",
    "        Configuration dictionary. Required key-value pairs:\n",
    "        `\"ensemble_shape\"` : tuple[int]\n",
    "            Ensemble shape. We assume this is a 1-dimensional tuple\n",
    "            with dimensions the population size.\n",
    "        `\"hyperparameter_raw_init_distributions\"` : `dict`\n",
    "            Dictionary that maps tuned hyperparameter names\n",
    "            to `torch.distributions.Distribution` of raw hyperparameter values.\n",
    "            Required keys:\n",
    "            `\"learning_rate\"`:\n",
    "                The learning rate of stochastic gradient descent.\n",
    "        `\"hyperparameter_raw_perturbs\"` : `dict`\n",
    "            Dictionary that maps tuned hyperparameter names\n",
    "            to `torch.distributions.Distribution` of additive noise.\n",
    "        `\"hyperparameter_transforms\"` : `dict`\n",
    "            Dictionary that maps tuned hyperparameter names\n",
    "            to transformations of raw hyperparameter values.\n",
    "        `\"improvement_threshold\"` : `float`\n",
    "            A new metric score has to be this much better\n",
    "            than the previous best to count as an improvement.\n",
    "        `\"minibatch_size\"` : `int`\n",
    "            Minibatch size to use in a training step.\n",
    "        `\"minibatch_size_eval\"` : `int`\n",
    "            Minibatch size to use in evaluation.\n",
    "            On CPU, should be about the same as `minibatch_size`.\n",
    "            On GPU, should be as big as possible without\n",
    "            incurring an Out of Memory error.\n",
    "        `\"pbt\"` : `bool`\n",
    "            Whether to use PBT updates in validations.\n",
    "            If `False`, the algorithm just samples hyperparameters at start,\n",
    "            then keeps them constant.\n",
    "        `\"steps_num\"` : `int`\n",
    "            Maximum number of training steps.\n",
    "        `\"steps_without_improvement`\" : `int`\n",
    "            If the number of training steps without improvement\n",
    "            exceeds this value, then training is stopped.\n",
    "        `\"valid_interval\"` : `int`\n",
    "            Frequency of evaluations, measured in number of training steps.\n",
    "        `\"welch_confidence_level\"` : `float`\n",
    "            The confidence level in Welch's t-test\n",
    "            that is used in determining if a population member\n",
    "            is to be replaced by another member with perturbed hyperparameters.\n",
    "        `\"welch_sample_size\"` : `int`\n",
    "            The last this many validation metrics are used\n",
    "            in Welch's t-test.\n",
    "    dataset_train : `dict`\n",
    "        The dataset to train the model on.\n",
    "    dataset_valid : `dict`\n",
    "        The dataset to evaluate the model on.\n",
    "    `get_loss` : `Callable[[dict, torch.Tensor], torch.Tensor]`\n",
    "        A function that maps a pair of model output and target value tensor\n",
    "        to a tensor of losses per ensemble member.\n",
    "    `get_metric` : `Callable[[dict, torch.Tensor], torch.Tensor]`\n",
    "        A function that maps a pair of model output and target value tensor\n",
    "        to a tensor of metrics per ensemble member.\n",
    "        We assume a greater metric is better.\n",
    "    `model` : `torch.nn.Module`\n",
    "        The model ensemble to tune.\n",
    "    `optimizer` : `Optimizer`\n",
    "        An optimizer that tracks the parameters of `model`.\n",
    "    indptr_key : `str`, optional\n",
    "        If the dataset has sequential entries,\n",
    "        then this is the key of the index pointer tensor.\n",
    "        Default: `\"indptr\"`.\n",
    "    target_key : `str`, optional\n",
    "        The key mapped to the target value tensor in the dataset.\n",
    "        Default: `\"target\"`\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    An output dictionary with the following key-value pairs:\n",
    "        `\"source mask\"` : `torch.Tensor`\n",
    "            The source masks of population members\n",
    "            that were replace by other members in a PBT update\n",
    "        `\"target indices\"` : `torch.Tensor`\n",
    "            The indices of population members\n",
    "            that the member where the source mask is to were replaced with.\n",
    "        `\"validation metric\"` : `torch.Tensor`\n",
    "            The validation metrics at evaluation steps.\n",
    "\n",
    "        In addition, for each tuned hyperparameter name,\n",
    "        we include a `torch.Tensor` of values per update.\n",
    "    \"\"\"\n",
    "    ensemble_shape = config[\"ensemble_shape\"]\n",
    "    if len(ensemble_shape) != 1:\n",
    "        raise ValueError(f\"The number of dimensions in the ensemble shape should be 1 for the  population size, but it is {len(ensemble_shape)}\")\n",
    "\n",
    "    config_local = dict(config)\n",
    "    log = defaultdict(list)\n",
    "\n",
    "    pbt_init(config_local, log)\n",
    "\n",
    "    update_model(config_local, model)\n",
    "    optimizer.update_config(config_local)\n",
    "\n",
    "    best_valid_metric = -torch.inf\n",
    "    progress_bar = tqdm.trange(config[\"steps_num\"])\n",
    "    steps_without_improvement = 0\n",
    "    train_dataloader = get_dataloader_random_reshuffle(\n",
    "        config,\n",
    "        dataset_train[\"features\"],\n",
    "        dataset_train[\"labels\"]\n",
    "    )\n",
    "\n",
    "    for step_id in progress_bar:\n",
    "        model.train()\n",
    "        minibatch = next(train_dataloader)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predict = model(minibatch[0])[0][...,0]\n",
    "        target = minibatch[1][0]\n",
    "\n",
    "        loss = get_loss(predict, target).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step_id % config[\"valid_interval\"] == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                split_name = \"validation\"\n",
    "                minibatch = next(train_dataloader)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predict = model(minibatch[0])[0][...,0]\n",
    "                target = minibatch[1][0]\n",
    "                \n",
    "                \n",
    "                metric = (predict.argmax(dim=-1) == target).to(config[\"float_dtype\"]).mean()\n",
    "                \n",
    "                # log[f\"{split_name} loss\"].append(loss)\n",
    "                log[f\"{split_name} metric\"].append(metric)\n",
    "                # print(\n",
    "                #     f\"{split_name} loss {loss.min().cpu().item():.4f}\"\n",
    "                # )\n",
    "                print(\n",
    "                    f\"{split_name} metric {metric.max().cpu().item():.4f}\"\n",
    "                )\n",
    "\n",
    "                best_last_metric = log[\"validation metric\"][-1].max()\n",
    "                print(\n",
    "                    f\"Best last metric {best_last_metric.cpu().item():.2f}\",\n",
    "                    flush=True\n",
    "                )\n",
    "                if (\n",
    "                    best_valid_metric + config[\"improvement_threshold\"]\n",
    "                ) < best_last_metric:\n",
    "                    print(\n",
    "                        f\"New best metric\",\n",
    "                        flush=True\n",
    "                    )\n",
    "                    best_valid_metric = best_last_metric\n",
    "                    steps_without_improvement = 0\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Best metric {best_valid_metric.cpu().item():.2f}\",\n",
    "                        flush=True\n",
    "                    )\n",
    "                    steps_without_improvement += config[\"valid_interval\"]\n",
    "                    if steps_without_improvement > config[\n",
    "                        \"steps_without_improvement\"\n",
    "                    ]:\n",
    "                        break\n",
    "\n",
    "                if config[\"pbt\"] and (len(log[\"validation metric\"]) >= config[\n",
    "                    \"welch_sample_size\"\n",
    "                ]):\n",
    "                    evaluations = torch.stack(\n",
    "                        log[\"validation metric\"][-config[\"welch_sample_size\"]:]\n",
    "                    )\n",
    "                    pbt_update(\n",
    "                        config_local, evaluations, log, optimizer.get_parameters()\n",
    "                    )\n",
    "\n",
    "                    update_model(config_local, model)\n",
    "                    optimizer.update_config(config_local)\n",
    "\n",
    "\n",
    "    progress_bar.close()\n",
    "    for key, value in log.items():\n",
    "        if isinstance(value, list):\n",
    "            log[key] = torch.stack(value)\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        embedding_dim = config[\"embedding_dim\"]\n",
    "        n_heads = config[\"n_heads\"]\n",
    "        block_num = config[\"block_num\"]\n",
    "        \n",
    "        # create embedding block\n",
    "        self.EmbeddingBlock = EmbeddingBlock(config, embedding_dim)\n",
    "        \n",
    "        # make repeated transformer block\n",
    "        blocks = []\n",
    "        for _ in range(block_num):\n",
    "            blocks.extend([\n",
    "                MultiHeadSelfAttentionBlock(n_heads, config, embedding_dim),\n",
    "                FeedForwardBlock(config, embedding_dim)\n",
    "            ])\n",
    "        self.MHA_FF_Block = nn.Sequential(*blocks)\n",
    "        \n",
    "        # use Linear to create logits\n",
    "        self.Linear = Linear(config, embedding_dim, 1)\n",
    "        \n",
    "        # use softmax\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded_inputs = self.EmbeddingBlock(input)\n",
    "        \n",
    "        out = self.MHA_FF_Block(embedded_inputs)\n",
    "        \n",
    "        logits = self.Linear(out)[\"features\"]\n",
    "        \n",
    "        logits = self.softmax(logits)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anu\\AppData\\Local\\Temp\\ipykernel_9128\\1019586205.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load('data/dataset_v2.pt', map_location=config[\"device\"])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.35 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 12.86 GiB is allocated by PyTorch, and 144.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/dataset_v2.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m dataset_train, dataset_valid \u001b[38;5;241m=\u001b[39m {}, {}\n\u001b[0;32m      3\u001b[0m dataset_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m], dataset_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m], dataset_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m], dataset_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      4\u001b[0m     dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m], dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][:,\u001b[38;5;241m0\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1361\u001b[0m             opened_zipfile,\n\u001b[0;32m   1362\u001b[0m             map_location,\n\u001b[0;32m   1363\u001b[0m             pickle_module,\n\u001b[0;32m   1364\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1365\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1366\u001b[0m         )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(\n\u001b[0;32m   1813\u001b[0m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[0;32m   1814\u001b[0m     )\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:1784\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1779\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1784\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   1785\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1786\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1787\u001b[0m )\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1790\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:1685\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_location\u001b[39m(storage, location):\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_restore_location(storage, map_location)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:601\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 601\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\serialization.py:540\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m    539\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\storage.py:279\u001b[0m, in \u001b[0;36m_StorageBase.to\u001b[1;34m(self, device, non_blocking)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, device: torch\u001b[38;5;241m.\u001b[39mdevice, non_blocking: _bool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    278\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[_StorageBase, TypedStorage]:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _to(\u001b[38;5;28mself\u001b[39m, device, non_blocking)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\_utils.py:88\u001b[0m, in \u001b[0;36m_to\u001b[1;34m(self, device, non_blocking)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse\n\u001b[0;32m     87\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 88\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     89\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.35 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 12.86 GiB is allocated by PyTorch, and 144.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "dataset = torch.load('data/dataset_v2.pt', map_location=config[\"device\"])\n",
    "dataset_train, dataset_valid = {}, {}\n",
    "dataset_train[\"features\"], dataset_valid[\"features\"], dataset_train[\"labels\"], dataset_valid[\"labels\"] = train_test_split(\n",
    "    dataset[\"features\"], dataset[\"labels\"][:,0], test_size=0.2, random_state=config['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.0600\n",
      "Best last metric 0.06\n",
      "New best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      " 10%|▉         | 496/5000 [00:07<01:08, 65.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1600\n",
      "Best last metric 0.16\n",
      "New best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1000/5000 [00:15<01:00, 66.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1600\n",
      "Best last metric 0.16\n",
      "Best metric 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1496/5000 [00:23<00:54, 64.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1600\n",
      "Best last metric 0.16\n",
      "Best metric 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2000/5000 [00:30<00:45, 66.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1800\n",
      "Best last metric 0.18\n",
      "New best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 2497/5000 [00:38<00:38, 65.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1600\n",
      "Best last metric 0.16\n",
      "Best metric 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2994/5000 [00:45<00:30, 66.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1500\n",
      "Best last metric 0.15\n",
      "Best metric 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 3498/5000 [00:53<00:22, 66.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.0600\n",
      "Best last metric 0.06\n",
      "Best metric 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 3995/5000 [01:01<00:15, 63.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1900\n",
      "Best last metric 0.19\n",
      "New best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 4499/5000 [01:08<00:07, 65.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation metric 0.1700\n",
      "Best last metric 0.17\n",
      "Best metric 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:16<00:00, 65.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config).to(config[\"device\"])\n",
    "optimizer = AdamW(model.parameters())\n",
    "\n",
    "log = train_supervised(\n",
    "    config,\n",
    "    dataset_train,\n",
    "    dataset_valid,\n",
    "    CrossEntropyLoss(),\n",
    "    get_accuracy,\n",
    "    model,\n",
    "    optimizer,\n",
    "    target_key=\"labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'dropout_p': tensor([[0.0022]], device='cuda:0'),\n",
       "             'epsilon': tensor([[2.4228e-09]], device='cuda:0'),\n",
       "             'first_moment_decay': tensor([[0.9281]], device='cuda:0'),\n",
       "             'learning_rate': tensor([[0.0005]], device='cuda:0'),\n",
       "             'second_moment_decay': tensor([[0.9996]], device='cuda:0'),\n",
       "             'weight_decay': tensor([[0.0112]], device='cuda:0'),\n",
       "             'validation metric': tensor([0.0600, 0.1600, 0.1600, 0.1600, 0.1800, 0.1600, 0.1500, 0.0600, 0.1900,\n",
       "                     0.1700], device='cuda:0')})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(log[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining metric\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.lineplot(log[\"training metric\"].cpu())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
