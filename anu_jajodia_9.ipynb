{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n",
        "# !pip install gymnasium"
      ],
      "metadata": {
        "id": "CwVKN7zztd0s"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "sJ7HddpNUypk"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from abc import (\n",
        "    ABC,\n",
        "    abstractmethod\n",
        ")\n",
        "from collections import defaultdict\n",
        "from collections.abc import (\n",
        "    Callable,\n",
        "    Iterable\n",
        ")\n",
        "import itertools\n",
        "import os\n",
        "import torch\n",
        "import tqdm\n",
        "import datasets\n",
        "\n",
        "from functions import (\n",
        "    pbt_init,\n",
        "    pbt_update,\n",
        "    get_dataloader_random_reshuffle,\n",
        "    to_ensembled,\n",
        "    DictReLU,\n",
        "    evaluate_model,\n",
        "    normalize_features,\n",
        "    Conv,\n",
        "    get_accuracy,\n",
        "    get_cross_entropy,\n",
        "    Linear,\n",
        "    Pool,\n",
        "    LayerNorm,\n",
        "    train_supervised,\n",
        "    AdamW,\n",
        "    Dropout\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "fvsxFfFKUypl"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"dataset_path\": \"uoft-cs/cifar10\",\n",
        "    \"dataset_preprocessed_path\": \"data/cifar10.pt\",\n",
        "    \"device\": \"cpu\",\n",
        "    \"ensemble_shape\": (16,),\n",
        "    \"float_dtype\": torch.float32,\n",
        "    \"hyperparameter_raw_init_distributions\": {\n",
        "        \"dropout_p\": torch.distributions.Uniform(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(.5, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"epsilon\": torch.distributions.Uniform(\n",
        "            torch.tensor(-10, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(-5, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"first_moment_decay\": torch.distributions.Uniform(\n",
        "            torch.tensor(-3, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"learning_rate\": torch.distributions.Uniform(\n",
        "            torch.tensor(-5, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(-1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"second_moment_decay\": torch.distributions.Uniform(\n",
        "            torch.tensor(-5, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(-1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"weight_decay\": torch.distributions.Uniform(\n",
        "            torch.tensor(-5, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(-1, device=\"cpu\", dtype=torch.float32)\n",
        "        )\n",
        "    },\n",
        "    \"hyperparameter_raw_perturb\": {\n",
        "        \"dropout_p\": torch.distributions.Normal(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(.1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"epsilon\": torch.distributions.Normal(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"first_moment_decay\": torch.distributions.Normal(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"learning_rate\": torch.distributions.Normal(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"second_moment_decay\": torch.distributions.Normal(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "        \"weight_decay\": torch.distributions.Normal(\n",
        "            torch.tensor(0, device=\"cpu\", dtype=torch.float32),\n",
        "            torch.tensor(1, device=\"cpu\", dtype=torch.float32)\n",
        "        ),\n",
        "    },\n",
        "    \"hyperparameter_transforms\": {\n",
        "        \"dropout_p\": lambda p: p.clip(0,1),\n",
        "        \"epsilon\": lambda log10: 10 ** log10,\n",
        "        \"first_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
        "        \"learning_rate\": lambda log10: 10 ** log10,\n",
        "        \"second_moment_decay\": lambda x: (1 - 10 ** x).clamp(0, 1),\n",
        "        \"weight_decay\": lambda log10: 10 ** log10,\n",
        "    },\n",
        "    \"improvement_threshold\": 1e-4,\n",
        "    \"minibatch_size\": 32,\n",
        "    \"minibatch_size_eval\": 32,\n",
        "    \"pbt\": True,\n",
        "    \"seed\": 0,\n",
        "    \"steps_num\": 10_001,\n",
        "    \"steps_without_improvement\": 10_000,\n",
        "    \"valid_interval\": 1000,\n",
        "    \"welch_confidence_level\": .95,\n",
        "    \"welch_sample_size\": 10,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G22_AYqUypl",
        "outputId": "2d3579df-4c86-4886-f310-8a9689ceb9fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d9de761beb0>"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ],
      "source": [
        "torch.manual_seed(config[\"seed\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "C94kdBJPUypl"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(config[\"dataset_preprocessed_path\"]):\n",
        "    dataset = datasets.load_dataset(\n",
        "        config[\"dataset_path\"]\n",
        "    ).with_format(\n",
        "        \"torch\",\n",
        "        device=config[\"device\"]\n",
        "    )\n",
        "    train, test = (\n",
        "        dataset[key]\n",
        "        for key in [\"train\", \"test\"]\n",
        "    )\n",
        "    train_valid = train.train_test_split(\n",
        "        seed=config[\"seed\"],\n",
        "        test_size=len(test),\n",
        "    )\n",
        "    train, valid = (\n",
        "        train_valid[key]\n",
        "        for key in [\"train\", \"test\"]\n",
        "    )\n",
        "\n",
        "    (\n",
        "        train_features,\n",
        "        valid_features,\n",
        "        test_features\n",
        "    ) = (\n",
        "        dataset[\"img\"].to(config[\"float_dtype\"])\n",
        "        for dataset in (train, valid, test)\n",
        "    )\n",
        "\n",
        "    print(train_features.std())\n",
        "\n",
        "    normalize_features(\n",
        "        train_features,\n",
        "        (valid_features, test_features)\n",
        "    )\n",
        "\n",
        "    print(train_features.std())\n",
        "\n",
        "    print(train[\"label\"].dtype)\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"train_features\": train_features,\n",
        "            \"train_labels\": train[\"label\"],\n",
        "            \"valid_features\": valid_features,\n",
        "            \"valid_labels\": valid[\"label\"],\n",
        "            \"test_features\": test_features,\n",
        "            \"test_labels\": test[\"label\"],\n",
        "        },\n",
        "        config[\"dataset_preprocessed_path\"]\n",
        "    )\n",
        "\n",
        "loaded = torch.load(\n",
        "    config[\"dataset_preprocessed_path\"],\n",
        "    weights_only=True,\n",
        "    map_location=config['device']\n",
        ")\n",
        "(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    valid_features,\n",
        "    valid_labels,\n",
        "    test_features,\n",
        "    test_labels\n",
        ") = (\n",
        "    loaded[key]\n",
        "    for key in (\n",
        "        \"train_features\",\n",
        "        \"train_labels\",\n",
        "        \"valid_features\",\n",
        "        \"valid_labels\",\n",
        "        \"test_features\",\n",
        "        \"test_labels\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResLayer(torch.nn.Module): # note: worked with Hao on this but wrote up own solutions\n",
        "    def __init__(\n",
        "        self, config: dict,\n",
        "        conv_in: int,\n",
        "        conv_out: int,\n",
        "        out_dims: int,\n",
        "        kernel_shape: tuple[int],\n",
        "\n",
        "    ):\n",
        "        super(ResLayer, self).__init__()\n",
        "\n",
        "\n",
        "        self.config = config\n",
        "        self.n = conv_in\n",
        "        self.m = conv_out\n",
        "        self.F_out = out_dims\n",
        "        self.kernel_shape = kernel_shape\n",
        "\n",
        "        self.F = torch.nn.Sequential(\n",
        "              LayerNorm(\n",
        "                  config,\n",
        "                  self.n,\n",
        "                  normalized_offset=2,\n",
        "              ),\n",
        "              Dropout(config),\n",
        "              Conv(\n",
        "                  config,\n",
        "                  self.n,\n",
        "                  (3,3),\n",
        "                  self.m,\n",
        "                  init_multiplier=2 ** .5\n",
        "              ),\n",
        "              DictReLU(),\n",
        "              LayerNorm(\n",
        "                  config,\n",
        "                  self.m,\n",
        "                  normalized_offset=2,\n",
        "              ),\n",
        "              Dropout(config),\n",
        "              Conv(\n",
        "                  config,\n",
        "                  self.m,\n",
        "                  (3,3),\n",
        "                  self.F_out,\n",
        "                  # init_multiplier=2 ** .5\n",
        "              )\n",
        "            )\n",
        "\n",
        "    def Q(self, x):\n",
        "        slicing_indices = [slice(None)] * (x.dim() - len(self.kernel_shape))\n",
        "\n",
        "        indices = []\n",
        "\n",
        "        for kern_dim in self.kernel_shape:\n",
        "            starting_index = (2 * (kern_dim - 1)) // 2\n",
        "            ending_index = -2 * (((kern_dim - 1) // 2) + ((kern_dim - 1) % 2))\n",
        "\n",
        "            s = slice(starting_index, None) if ending_index == 0 else slice(starting_index, ending_index)\n",
        "\n",
        "            indices.append(s)\n",
        "\n",
        "        slicing_indices += indices\n",
        "\n",
        "        return x[tuple(slicing_indices)]\n",
        "\n",
        "    def P(self, x, fx):\n",
        "\n",
        "        Qx = self.Q(x)\n",
        "\n",
        "        indices = torch.arange(self.F_out, device=self.config[\"device\"])\n",
        "        indices = indices % self.n\n",
        "\n",
        "        feature_dim = -(len(self.kernel_shape) + 1)\n",
        "\n",
        "\n",
        "        Px = torch.index_select(\n",
        "            Qx,\n",
        "            dim=feature_dim,\n",
        "            index=indices\n",
        "            )\n",
        "        return Px\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, batch: dict) -> dict:\n",
        "        x = batch[\"features\"]\n",
        "\n",
        "\n",
        "        Fx = self.F(batch)[\"features\"]\n",
        "\n",
        "        Px = self.P(x, Fx)\n",
        "\n",
        "        features = Px + Fx\n",
        "\n",
        "        return batch | {\"features\": features}"
      ],
      "metadata": {
        "id": "l2B2jh9zZCFc"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbga5cO2Uypl",
        "outputId": "3bf92d5c-8680-45d0-8322-478b75c6bd48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10001 [00:00<?, ?it/s]\n",
            "  0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/313 [00:01<07:52,  1.51s/it]\u001b[A\n",
            "  1%|          | 2/313 [00:03<08:03,  1.55s/it]\u001b[A\n",
            "  1%|          | 3/313 [00:04<07:55,  1.53s/it]\u001b[A\n",
            "  1%|▏         | 4/313 [00:05<06:55,  1.34s/it]\u001b[A\n",
            "  2%|▏         | 5/313 [00:06<06:20,  1.24s/it]\u001b[A\n",
            "  2%|▏         | 6/313 [00:07<06:00,  1.17s/it]\u001b[A\n",
            "  2%|▏         | 7/313 [00:08<05:48,  1.14s/it]\u001b[A\n",
            "  3%|▎         | 8/313 [00:09<05:40,  1.11s/it]\u001b[A\n",
            "  3%|▎         | 9/313 [00:10<05:33,  1.10s/it]\u001b[A\n",
            "  3%|▎         | 10/313 [00:12<05:28,  1.09s/it]\u001b[A\n",
            "  4%|▎         | 11/313 [00:13<05:25,  1.08s/it]\u001b[A\n",
            "  4%|▍         | 12/313 [00:14<05:23,  1.08s/it]\u001b[A\n",
            "  4%|▍         | 13/313 [00:15<05:51,  1.17s/it]\u001b[A\n",
            "  4%|▍         | 14/313 [00:17<06:20,  1.27s/it]\u001b[A\n",
            "  5%|▍         | 15/313 [00:18<06:42,  1.35s/it]\u001b[A\n",
            "  5%|▌         | 16/313 [00:19<06:22,  1.29s/it]\u001b[A\n",
            "  5%|▌         | 17/313 [00:20<06:00,  1.22s/it]\u001b[A\n",
            "  6%|▌         | 18/313 [00:21<05:45,  1.17s/it]\u001b[A\n",
            "  6%|▌         | 19/313 [00:22<05:34,  1.14s/it]\u001b[A\n",
            "  6%|▋         | 20/313 [00:23<05:27,  1.12s/it]\u001b[A\n",
            "  7%|▋         | 21/313 [00:25<05:21,  1.10s/it]\u001b[A\n",
            "  7%|▋         | 22/313 [00:26<05:14,  1.08s/it]\u001b[A\n",
            "  7%|▋         | 23/313 [00:27<05:09,  1.07s/it]\u001b[A\n",
            "  8%|▊         | 24/313 [00:28<05:05,  1.06s/it]\u001b[A\n",
            "  8%|▊         | 25/313 [00:30<06:25,  1.34s/it]\u001b[A\n",
            "  8%|▊         | 26/313 [00:32<07:13,  1.51s/it]\u001b[A\n",
            "  9%|▊         | 27/313 [00:33<06:59,  1.47s/it]\u001b[A\n",
            "  9%|▉         | 28/313 [00:34<06:22,  1.34s/it]\u001b[A\n",
            "  9%|▉         | 29/313 [00:35<05:55,  1.25s/it]\u001b[A\n",
            " 10%|▉         | 30/313 [00:36<05:36,  1.19s/it]\u001b[A\n",
            " 10%|▉         | 31/313 [00:37<05:22,  1.14s/it]\u001b[A\n",
            " 10%|█         | 32/313 [00:38<05:12,  1.11s/it]\u001b[A\n",
            " 11%|█         | 33/313 [00:39<05:04,  1.09s/it]\u001b[A\n",
            " 11%|█         | 34/313 [00:40<04:59,  1.07s/it]\u001b[A\n",
            " 11%|█         | 35/313 [00:41<04:54,  1.06s/it]\u001b[A\n",
            " 12%|█▏        | 36/313 [00:42<04:50,  1.05s/it]\u001b[A\n",
            " 12%|█▏        | 37/313 [00:44<05:21,  1.17s/it]\u001b[A\n",
            " 12%|█▏        | 38/313 [00:45<05:48,  1.27s/it]\u001b[A\n",
            " 12%|█▏        | 39/313 [00:47<06:07,  1.34s/it]\u001b[A\n",
            " 13%|█▎        | 40/313 [00:48<05:49,  1.28s/it]\u001b[A\n",
            " 13%|█▎        | 41/313 [00:49<05:29,  1.21s/it]\u001b[A\n",
            " 13%|█▎        | 42/313 [00:50<05:14,  1.16s/it]\u001b[A\n",
            " 14%|█▎        | 43/313 [00:51<05:04,  1.13s/it]\u001b[A\n",
            " 14%|█▍        | 44/313 [00:52<04:57,  1.11s/it]\u001b[A\n",
            " 14%|█▍        | 45/313 [00:53<04:51,  1.09s/it]\u001b[A\n",
            " 15%|█▍        | 46/313 [00:54<04:47,  1.08s/it]\u001b[A\n",
            " 15%|█▌        | 47/313 [00:55<04:44,  1.07s/it]\u001b[A\n",
            " 15%|█▌        | 48/313 [00:56<04:41,  1.06s/it]\u001b[A\n",
            " 16%|█▌        | 49/313 [00:57<04:50,  1.10s/it]\u001b[A\n",
            " 16%|█▌        | 50/313 [00:59<05:21,  1.22s/it]\u001b[A\n",
            " 16%|█▋        | 51/313 [01:01<05:51,  1.34s/it]\u001b[A\n",
            " 17%|█▋        | 52/313 [01:02<06:13,  1.43s/it]\u001b[A\n",
            " 17%|█▋        | 53/313 [01:04<06:21,  1.47s/it]\u001b[A\n",
            " 17%|█▋        | 54/313 [01:05<06:28,  1.50s/it]\u001b[A\n",
            " 18%|█▊        | 55/313 [01:06<05:58,  1.39s/it]\u001b[A\n",
            " 18%|█▊        | 56/313 [01:07<05:30,  1.29s/it]\u001b[A\n",
            " 18%|█▊        | 57/313 [01:09<05:11,  1.22s/it]\u001b[A\n",
            " 19%|█▊        | 58/313 [01:10<04:57,  1.17s/it]\u001b[A\n",
            " 19%|█▉        | 59/313 [01:11<04:45,  1.12s/it]\u001b[A\n",
            " 19%|█▉        | 60/313 [01:12<04:37,  1.10s/it]\u001b[A\n",
            " 19%|█▉        | 61/313 [01:13<04:31,  1.08s/it]\u001b[A\n",
            " 20%|█▉        | 62/313 [01:14<04:56,  1.18s/it]\u001b[A\n",
            " 20%|██        | 63/313 [01:16<05:21,  1.29s/it]\u001b[A\n",
            " 20%|██        | 64/313 [01:17<05:38,  1.36s/it]\u001b[A\n",
            " 21%|██        | 65/313 [01:18<05:18,  1.28s/it]\u001b[A\n",
            " 21%|██        | 66/313 [01:19<04:59,  1.21s/it]\u001b[A\n",
            " 21%|██▏       | 67/313 [01:20<04:46,  1.16s/it]\u001b[A\n",
            " 22%|██▏       | 68/313 [01:21<04:36,  1.13s/it]\u001b[A\n",
            " 22%|██▏       | 69/313 [01:22<04:29,  1.10s/it]\u001b[A\n",
            " 22%|██▏       | 70/313 [01:24<04:24,  1.09s/it]\u001b[A\n",
            " 23%|██▎       | 71/313 [01:25<04:21,  1.08s/it]\u001b[A\n",
            " 23%|██▎       | 72/313 [01:26<04:18,  1.07s/it]\u001b[A\n",
            " 23%|██▎       | 73/313 [01:27<04:15,  1.06s/it]\u001b[A\n",
            " 24%|██▎       | 74/313 [01:28<04:23,  1.10s/it]\u001b[A\n",
            " 24%|██▍       | 75/313 [01:29<04:51,  1.23s/it]\u001b[A\n",
            " 24%|██▍       | 76/313 [01:31<05:12,  1.32s/it]\u001b[A\n",
            " 25%|██▍       | 77/313 [01:32<05:06,  1.30s/it]\u001b[A\n",
            " 25%|██▍       | 78/313 [01:33<04:48,  1.23s/it]\u001b[A\n",
            " 25%|██▌       | 79/313 [01:34<04:34,  1.17s/it]\u001b[A\n",
            " 26%|██▌       | 80/313 [01:35<04:24,  1.13s/it]\u001b[A\n",
            " 26%|██▌       | 81/313 [01:36<04:16,  1.11s/it]\u001b[A\n",
            " 26%|██▌       | 82/313 [01:37<04:10,  1.09s/it]\u001b[A\n",
            " 27%|██▋       | 83/313 [01:38<04:06,  1.07s/it]\u001b[A\n",
            " 27%|██▋       | 84/313 [01:39<04:04,  1.07s/it]\u001b[A\n",
            " 27%|██▋       | 85/313 [01:41<04:02,  1.06s/it]\u001b[A\n",
            " 27%|██▋       | 86/313 [01:42<04:00,  1.06s/it]\u001b[A\n",
            " 28%|██▊       | 87/313 [01:43<04:29,  1.19s/it]\u001b[A\n",
            " 28%|██▊       | 88/313 [01:45<04:52,  1.30s/it]\u001b[A\n",
            " 28%|██▊       | 89/313 [01:46<05:12,  1.40s/it]\u001b[A\n",
            " 29%|██▉       | 90/313 [01:48<05:14,  1.41s/it]\u001b[A\n",
            " 29%|██▉       | 91/313 [01:49<05:20,  1.44s/it]\u001b[A\n",
            " 29%|██▉       | 92/313 [01:51<05:25,  1.47s/it]\u001b[A\n",
            " 30%|██▉       | 93/313 [01:52<04:55,  1.34s/it]\u001b[A\n",
            " 30%|███       | 94/313 [01:53<04:33,  1.25s/it]\u001b[A\n",
            " 30%|███       | 95/313 [01:54<04:18,  1.19s/it]\u001b[A\n",
            " 31%|███       | 96/313 [01:55<04:08,  1.14s/it]\u001b[A\n",
            " 31%|███       | 97/313 [01:56<04:01,  1.12s/it]\u001b[A\n",
            " 31%|███▏      | 98/313 [01:57<04:21,  1.22s/it]\u001b[A\n",
            " 32%|███▏      | 99/313 [01:59<04:40,  1.31s/it]\u001b[A\n",
            " 32%|███▏      | 100/313 [02:01<04:54,  1.38s/it]\u001b[A\n",
            " 32%|███▏      | 101/313 [02:02<04:31,  1.28s/it]\u001b[A\n",
            " 33%|███▎      | 102/313 [02:03<04:17,  1.22s/it]\u001b[A\n",
            " 33%|███▎      | 103/313 [02:04<04:04,  1.17s/it]\u001b[A\n",
            " 33%|███▎      | 104/313 [02:05<03:57,  1.14s/it]\u001b[A\n",
            " 34%|███▎      | 105/313 [02:06<03:51,  1.11s/it]\u001b[A\n",
            " 34%|███▍      | 106/313 [02:07<03:47,  1.10s/it]\u001b[A\n",
            " 34%|███▍      | 107/313 [02:08<03:44,  1.09s/it]\u001b[A\n",
            " 35%|███▍      | 108/313 [02:09<03:41,  1.08s/it]\u001b[A\n",
            " 35%|███▍      | 109/313 [02:10<03:38,  1.07s/it]\u001b[A\n",
            " 35%|███▌      | 110/313 [02:11<03:52,  1.15s/it]\u001b[A\n",
            " 35%|███▌      | 111/313 [02:13<04:14,  1.26s/it]\u001b[A\n",
            " 36%|███▌      | 112/313 [02:14<04:30,  1.34s/it]\u001b[A\n",
            " 36%|███▌      | 113/313 [02:16<04:15,  1.28s/it]\u001b[A\n",
            " 36%|███▋      | 114/313 [02:17<04:01,  1.21s/it]\u001b[A\n",
            " 37%|███▋      | 115/313 [02:18<03:51,  1.17s/it]\u001b[A\n",
            " 37%|███▋      | 116/313 [02:19<03:43,  1.13s/it]\u001b[A\n",
            " 37%|███▋      | 117/313 [02:20<03:36,  1.11s/it]\u001b[A\n",
            " 38%|███▊      | 118/313 [02:21<03:32,  1.09s/it]\u001b[A\n",
            " 38%|███▊      | 119/313 [02:22<03:29,  1.08s/it]\u001b[A\n",
            " 38%|███▊      | 120/313 [02:23<03:27,  1.08s/it]\u001b[A\n",
            " 39%|███▊      | 121/313 [02:24<03:25,  1.07s/it]\u001b[A\n",
            " 39%|███▉      | 122/313 [02:25<03:32,  1.11s/it]\u001b[A\n",
            " 39%|███▉      | 123/313 [02:27<03:53,  1.23s/it]\u001b[A\n",
            " 40%|███▉      | 124/313 [02:28<04:09,  1.32s/it]\u001b[A\n",
            " 40%|███▉      | 125/313 [02:29<04:03,  1.30s/it]\u001b[A\n",
            " 40%|████      | 126/313 [02:31<03:48,  1.22s/it]\u001b[A\n",
            " 41%|████      | 127/313 [02:32<03:37,  1.17s/it]\u001b[A\n",
            " 41%|████      | 128/313 [02:33<03:31,  1.14s/it]\u001b[A\n",
            " 41%|████      | 129/313 [02:34<03:24,  1.11s/it]\u001b[A\n",
            " 42%|████▏     | 130/313 [02:35<03:19,  1.09s/it]\u001b[A\n",
            " 42%|████▏     | 131/313 [02:36<03:17,  1.08s/it]\u001b[A\n",
            " 42%|████▏     | 132/313 [02:37<03:14,  1.07s/it]\u001b[A\n",
            " 42%|████▏     | 133/313 [02:38<03:12,  1.07s/it]\u001b[A\n",
            " 43%|████▎     | 134/313 [02:39<03:13,  1.08s/it]\u001b[A\n",
            " 43%|████▎     | 135/313 [02:41<03:35,  1.21s/it]\u001b[A\n",
            " 43%|████▎     | 136/313 [02:42<03:51,  1.31s/it]\u001b[A\n",
            " 44%|████▍     | 137/313 [02:44<03:59,  1.36s/it]\u001b[A\n",
            " 44%|████▍     | 138/313 [02:45<03:42,  1.27s/it]\u001b[A\n",
            " 44%|████▍     | 139/313 [02:46<03:29,  1.21s/it]\u001b[A\n",
            " 45%|████▍     | 140/313 [02:47<03:21,  1.17s/it]\u001b[A\n",
            " 45%|████▌     | 141/313 [02:48<03:14,  1.13s/it]\u001b[A\n",
            " 45%|████▌     | 142/313 [02:49<03:08,  1.11s/it]\u001b[A\n",
            " 46%|████▌     | 143/313 [02:50<03:05,  1.09s/it]\u001b[A\n",
            " 46%|████▌     | 144/313 [02:51<03:02,  1.08s/it]\u001b[A\n",
            " 46%|████▋     | 145/313 [02:52<03:00,  1.07s/it]\u001b[A\n",
            " 47%|████▋     | 146/313 [02:53<02:57,  1.06s/it]\u001b[A\n",
            " 47%|████▋     | 147/313 [02:54<03:12,  1.16s/it]\u001b[A\n",
            " 47%|████▋     | 148/313 [02:56<03:30,  1.28s/it]\u001b[A\n",
            " 48%|████▊     | 149/313 [02:58<03:44,  1.37s/it]\u001b[A\n",
            " 48%|████▊     | 150/313 [02:59<03:27,  1.27s/it]\u001b[A\n",
            " 48%|████▊     | 151/313 [03:00<03:15,  1.21s/it]\u001b[A\n",
            " 49%|████▊     | 152/313 [03:01<03:06,  1.16s/it]\u001b[A\n",
            " 49%|████▉     | 153/313 [03:02<02:59,  1.12s/it]\u001b[A\n",
            " 49%|████▉     | 154/313 [03:03<02:56,  1.11s/it]\u001b[A\n",
            " 50%|████▉     | 155/313 [03:04<02:52,  1.09s/it]\u001b[A\n",
            " 50%|████▉     | 156/313 [03:05<02:49,  1.08s/it]\u001b[A\n",
            " 50%|█████     | 157/313 [03:06<02:46,  1.07s/it]\u001b[A\n",
            " 50%|█████     | 158/313 [03:07<02:45,  1.07s/it]\u001b[A\n",
            " 51%|█████     | 159/313 [03:08<02:55,  1.14s/it]\u001b[A\n",
            " 51%|█████     | 160/313 [03:10<03:11,  1.25s/it]\u001b[A\n",
            " 51%|█████▏    | 161/313 [03:11<03:24,  1.35s/it]\u001b[A\n",
            " 52%|█████▏    | 162/313 [03:13<03:15,  1.29s/it]\u001b[A\n",
            " 52%|█████▏    | 163/313 [03:14<03:02,  1.21s/it]\u001b[A\n",
            " 52%|█████▏    | 164/313 [03:15<02:53,  1.17s/it]\u001b[A\n",
            " 53%|█████▎    | 165/313 [03:16<02:46,  1.13s/it]\u001b[A\n",
            " 53%|█████▎    | 166/313 [03:17<02:42,  1.10s/it]\u001b[A\n",
            " 53%|█████▎    | 167/313 [03:18<02:38,  1.09s/it]\u001b[A\n",
            " 54%|█████▎    | 168/313 [03:19<02:35,  1.08s/it]\u001b[A\n",
            " 54%|█████▍    | 169/313 [03:20<02:33,  1.07s/it]\u001b[A\n",
            " 54%|█████▍    | 170/313 [03:21<02:31,  1.06s/it]\u001b[A\n",
            " 55%|█████▍    | 171/313 [03:22<02:32,  1.07s/it]\u001b[A\n",
            " 55%|█████▍    | 172/313 [03:24<02:49,  1.20s/it]\u001b[A\n",
            " 55%|█████▌    | 173/313 [03:25<03:03,  1.31s/it]\u001b[A\n",
            " 56%|█████▌    | 174/313 [03:27<03:09,  1.36s/it]\u001b[A\n",
            " 56%|█████▌    | 175/313 [03:28<02:55,  1.27s/it]\u001b[A\n",
            " 56%|█████▌    | 176/313 [03:29<02:44,  1.20s/it]\u001b[A\n",
            " 57%|█████▋    | 177/313 [03:30<02:37,  1.16s/it]\u001b[A\n",
            " 57%|█████▋    | 178/313 [03:31<02:31,  1.13s/it]\u001b[A\n",
            " 57%|█████▋    | 179/313 [03:32<02:27,  1.10s/it]\u001b[A\n",
            " 58%|█████▊    | 180/313 [03:33<02:26,  1.10s/it]\u001b[A\n",
            " 58%|█████▊    | 181/313 [03:34<02:23,  1.08s/it]\u001b[A\n",
            " 58%|█████▊    | 182/313 [03:35<02:20,  1.07s/it]\u001b[A\n",
            " 58%|█████▊    | 183/313 [03:36<02:18,  1.06s/it]\u001b[A\n",
            " 59%|█████▉    | 184/313 [03:37<02:29,  1.16s/it]\u001b[A\n",
            " 59%|█████▉    | 185/313 [03:39<02:42,  1.27s/it]\u001b[A\n",
            " 59%|█████▉    | 186/313 [03:41<02:52,  1.36s/it]\u001b[A\n",
            " 60%|█████▉    | 187/313 [03:42<02:44,  1.30s/it]\u001b[A\n",
            " 60%|██████    | 188/313 [03:43<02:33,  1.23s/it]\u001b[A\n",
            " 60%|██████    | 189/313 [03:44<02:25,  1.17s/it]\u001b[A\n",
            " 61%|██████    | 190/313 [03:45<02:20,  1.14s/it]\u001b[A\n",
            " 61%|██████    | 191/313 [03:46<02:16,  1.12s/it]\u001b[A\n",
            " 61%|██████▏   | 192/313 [03:47<02:12,  1.10s/it]\u001b[A\n",
            " 62%|██████▏   | 193/313 [03:48<02:09,  1.08s/it]\u001b[A\n",
            " 62%|██████▏   | 194/313 [03:49<02:07,  1.07s/it]\u001b[A\n",
            " 62%|██████▏   | 195/313 [03:50<02:05,  1.07s/it]\u001b[A\n",
            " 63%|██████▎   | 196/313 [03:51<02:07,  1.09s/it]\u001b[A\n",
            " 63%|██████▎   | 197/313 [03:53<02:21,  1.22s/it]\u001b[A\n",
            " 63%|██████▎   | 198/313 [03:54<02:30,  1.31s/it]\u001b[A\n",
            " 64%|██████▎   | 199/313 [03:56<02:33,  1.34s/it]\u001b[A\n",
            " 64%|██████▍   | 200/313 [03:57<02:22,  1.26s/it]\u001b[A\n",
            " 64%|██████▍   | 201/313 [03:58<02:13,  1.19s/it]\u001b[A\n",
            " 65%|██████▍   | 202/313 [03:59<02:07,  1.15s/it]\u001b[A\n",
            " 65%|██████▍   | 203/313 [04:00<02:02,  1.12s/it]\u001b[A\n",
            " 65%|██████▌   | 204/313 [04:01<01:59,  1.09s/it]\u001b[A\n",
            " 65%|██████▌   | 205/313 [04:02<01:57,  1.09s/it]\u001b[A\n",
            " 66%|██████▌   | 206/313 [04:03<01:56,  1.09s/it]\u001b[A\n",
            " 66%|██████▌   | 207/313 [04:04<01:54,  1.08s/it]\u001b[A\n",
            " 66%|██████▋   | 208/313 [04:05<01:51,  1.07s/it]\u001b[A\n",
            " 67%|██████▋   | 209/313 [04:07<02:02,  1.18s/it]\u001b[A\n",
            " 67%|██████▋   | 210/313 [04:08<02:11,  1.28s/it]\u001b[A\n",
            " 67%|██████▋   | 211/313 [04:10<02:19,  1.36s/it]\u001b[A\n",
            " 68%|██████▊   | 212/313 [04:11<02:10,  1.29s/it]\u001b[A\n",
            " 68%|██████▊   | 213/313 [04:12<02:02,  1.22s/it]\u001b[A\n",
            " 68%|██████▊   | 214/313 [04:13<01:56,  1.18s/it]\u001b[A\n",
            " 69%|██████▊   | 215/313 [04:14<01:51,  1.14s/it]\u001b[A\n",
            " 69%|██████▉   | 216/313 [04:15<01:47,  1.11s/it]\u001b[A\n",
            " 69%|██████▉   | 217/313 [04:16<01:44,  1.09s/it]\u001b[A\n",
            " 70%|██████▉   | 218/313 [04:17<01:42,  1.08s/it]\u001b[A\n",
            " 70%|██████▉   | 219/313 [04:18<01:40,  1.07s/it]\u001b[A\n",
            " 70%|███████   | 220/313 [04:19<01:38,  1.06s/it]\u001b[A\n",
            " 71%|███████   | 221/313 [04:21<01:41,  1.10s/it]\u001b[A\n",
            " 71%|███████   | 222/313 [04:22<01:51,  1.22s/it]\u001b[A\n",
            " 71%|███████   | 223/313 [04:24<01:59,  1.32s/it]\u001b[A\n",
            " 72%|███████▏  | 224/313 [04:25<01:59,  1.35s/it]\u001b[A\n",
            " 72%|███████▏  | 225/313 [04:26<01:52,  1.28s/it]\u001b[A\n",
            " 72%|███████▏  | 226/313 [04:27<01:45,  1.21s/it]\u001b[A\n",
            " 73%|███████▎  | 227/313 [04:28<01:39,  1.16s/it]\u001b[A\n",
            " 73%|███████▎  | 228/313 [04:29<01:35,  1.12s/it]\u001b[A\n",
            " 73%|███████▎  | 229/313 [04:30<01:32,  1.10s/it]\u001b[A\n",
            " 73%|███████▎  | 230/313 [04:31<01:29,  1.08s/it]\u001b[A\n",
            " 74%|███████▍  | 231/313 [04:32<01:28,  1.08s/it]\u001b[A\n",
            " 74%|███████▍  | 232/313 [04:33<01:27,  1.08s/it]\u001b[A\n",
            " 74%|███████▍  | 233/313 [04:35<01:25,  1.07s/it]\u001b[A\n",
            " 75%|███████▍  | 234/313 [04:36<01:35,  1.21s/it]\u001b[A\n",
            " 75%|███████▌  | 235/313 [04:38<01:42,  1.32s/it]\u001b[A\n",
            " 75%|███████▌  | 236/313 [04:39<01:46,  1.38s/it]\u001b[A\n",
            " 76%|███████▌  | 237/313 [04:40<01:37,  1.29s/it]\u001b[A\n",
            " 76%|███████▌  | 238/313 [04:41<01:31,  1.22s/it]\u001b[A\n",
            " 76%|███████▋  | 239/313 [04:42<01:26,  1.17s/it]\u001b[A\n",
            " 77%|███████▋  | 240/313 [04:43<01:22,  1.13s/it]\u001b[A\n",
            " 77%|███████▋  | 241/313 [04:44<01:19,  1.11s/it]\u001b[A\n",
            " 77%|███████▋  | 242/313 [04:45<01:17,  1.09s/it]\u001b[A\n",
            " 78%|███████▊  | 243/313 [04:47<01:15,  1.08s/it]\u001b[A\n",
            " 78%|███████▊  | 244/313 [04:48<01:14,  1.08s/it]\u001b[A\n",
            " 78%|███████▊  | 245/313 [04:49<01:12,  1.07s/it]\u001b[A\n",
            " 79%|███████▊  | 246/313 [04:50<01:17,  1.16s/it]\u001b[A\n",
            " 79%|███████▉  | 247/313 [04:52<01:24,  1.28s/it]\u001b[A\n",
            " 79%|███████▉  | 248/313 [04:53<01:28,  1.37s/it]\u001b[A\n",
            " 80%|███████▉  | 249/313 [04:54<01:23,  1.31s/it]\u001b[A\n",
            " 80%|███████▉  | 250/313 [04:55<01:17,  1.23s/it]\u001b[A\n",
            " 80%|████████  | 251/313 [04:56<01:13,  1.18s/it]\u001b[A\n",
            " 81%|████████  | 252/313 [04:58<01:10,  1.15s/it]\u001b[A\n",
            " 81%|████████  | 253/313 [04:59<01:07,  1.12s/it]\u001b[A\n",
            " 81%|████████  | 254/313 [05:00<01:05,  1.10s/it]\u001b[A\n",
            " 81%|████████▏ | 255/313 [05:01<01:03,  1.09s/it]\u001b[A\n",
            " 82%|████████▏ | 256/313 [05:02<01:01,  1.09s/it]\u001b[A\n",
            " 82%|████████▏ | 257/313 [05:03<01:07,  1.21s/it]\u001b[A\n",
            " 82%|████████▏ | 258/313 [05:05<01:15,  1.37s/it]\u001b[A\n",
            " 83%|████████▎ | 259/313 [05:07<01:19,  1.46s/it]\u001b[A\n",
            " 83%|████████▎ | 260/313 [05:08<01:22,  1.55s/it]\u001b[A\n",
            " 83%|████████▎ | 261/313 [05:10<01:21,  1.56s/it]\u001b[A\n",
            " 84%|████████▎ | 262/313 [05:11<01:14,  1.45s/it]\u001b[A\n",
            " 84%|████████▍ | 263/313 [05:12<01:06,  1.34s/it]\u001b[A\n",
            " 84%|████████▍ | 264/313 [05:13<01:01,  1.26s/it]\u001b[A\n",
            " 85%|████████▍ | 265/313 [05:14<00:57,  1.19s/it]\u001b[A\n",
            " 85%|████████▍ | 266/313 [05:15<00:53,  1.15s/it]\u001b[A\n",
            " 85%|████████▌ | 267/313 [05:17<00:51,  1.12s/it]\u001b[A\n",
            " 86%|████████▌ | 268/313 [05:18<00:49,  1.10s/it]\u001b[A\n",
            " 86%|████████▌ | 269/313 [05:19<00:47,  1.08s/it]\u001b[A\n",
            " 86%|████████▋ | 270/313 [05:20<00:46,  1.07s/it]\u001b[A\n",
            " 87%|████████▋ | 271/313 [05:21<00:45,  1.09s/it]\u001b[A\n",
            " 87%|████████▋ | 272/313 [05:22<00:50,  1.23s/it]\u001b[A\n",
            " 87%|████████▋ | 273/313 [05:24<00:53,  1.33s/it]\u001b[A\n",
            " 88%|████████▊ | 274/313 [05:25<00:53,  1.36s/it]\u001b[A\n",
            " 88%|████████▊ | 275/313 [05:26<00:48,  1.27s/it]\u001b[A\n",
            " 88%|████████▊ | 276/313 [05:27<00:44,  1.21s/it]\u001b[A\n",
            " 88%|████████▊ | 277/313 [05:29<00:41,  1.16s/it]\u001b[A\n",
            " 89%|████████▉ | 278/313 [05:30<00:39,  1.13s/it]\u001b[A\n",
            " 89%|████████▉ | 279/313 [05:31<00:37,  1.10s/it]\u001b[A\n",
            " 89%|████████▉ | 280/313 [05:32<00:35,  1.08s/it]\u001b[A\n",
            " 90%|████████▉ | 281/313 [05:33<00:34,  1.07s/it]\u001b[A\n",
            " 90%|█████████ | 282/313 [05:34<00:33,  1.07s/it]\u001b[A\n",
            " 90%|█████████ | 283/313 [05:35<00:31,  1.06s/it]\u001b[A\n",
            " 91%|█████████ | 284/313 [05:36<00:34,  1.18s/it]\u001b[A\n",
            " 91%|█████████ | 285/313 [05:38<00:35,  1.28s/it]\u001b[A\n",
            " 91%|█████████▏| 286/313 [05:39<00:36,  1.36s/it]\u001b[A\n",
            " 92%|█████████▏| 287/313 [05:40<00:32,  1.27s/it]\u001b[A\n",
            " 92%|█████████▏| 288/313 [05:42<00:30,  1.24s/it]\u001b[A\n",
            " 92%|█████████▏| 289/313 [05:43<00:31,  1.33s/it]\u001b[A\n",
            " 93%|█████████▎| 290/313 [05:45<00:32,  1.40s/it]\u001b[A\n",
            " 93%|█████████▎| 291/313 [05:46<00:29,  1.36s/it]\u001b[A\n",
            " 93%|█████████▎| 292/313 [05:47<00:26,  1.27s/it]\u001b[A\n",
            " 94%|█████████▎| 293/313 [05:48<00:24,  1.21s/it]\u001b[A\n",
            " 94%|█████████▍| 294/313 [05:49<00:22,  1.16s/it]\u001b[A\n",
            " 94%|█████████▍| 295/313 [05:51<00:22,  1.24s/it]\u001b[A\n",
            " 95%|█████████▍| 296/313 [05:52<00:22,  1.33s/it]\u001b[A\n",
            " 95%|█████████▍| 297/313 [05:54<00:22,  1.39s/it]\u001b[A\n",
            " 95%|█████████▌| 298/313 [05:55<00:19,  1.31s/it]\u001b[A\n",
            " 96%|█████████▌| 299/313 [05:56<00:17,  1.23s/it]\u001b[A\n",
            " 96%|█████████▌| 300/313 [05:57<00:15,  1.17s/it]\u001b[A\n",
            " 96%|█████████▌| 301/313 [05:58<00:13,  1.14s/it]\u001b[A\n",
            " 96%|█████████▋| 302/313 [05:59<00:12,  1.11s/it]\u001b[A\n",
            " 97%|█████████▋| 303/313 [06:00<00:10,  1.09s/it]\u001b[A\n",
            " 97%|█████████▋| 304/313 [06:01<00:09,  1.08s/it]\u001b[A\n",
            " 97%|█████████▋| 305/313 [06:02<00:08,  1.08s/it]\u001b[A\n",
            " 98%|█████████▊| 306/313 [06:03<00:07,  1.08s/it]\u001b[A\n",
            " 98%|█████████▊| 307/313 [06:04<00:06,  1.13s/it]\u001b[A\n",
            " 98%|█████████▊| 308/313 [06:06<00:06,  1.25s/it]\u001b[A\n",
            " 99%|█████████▊| 309/313 [06:07<00:05,  1.34s/it]\u001b[A\n",
            " 99%|█████████▉| 310/313 [06:09<00:03,  1.29s/it]\u001b[A\n",
            " 99%|█████████▉| 311/313 [06:10<00:02,  1.25s/it]\u001b[A\n",
            "100%|█████████▉| 312/313 [06:11<00:01,  1.18s/it]\u001b[A\n",
            "100%|██████████| 313/313 [06:11<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation metric 0.1465\n",
            "Best last metric 0.15\n",
            "New best metric\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 22/10001 [07:56<13:19:39,  4.81s/it]"
          ]
        }
      ],
      "source": [
        "model = torch.nn.Sequential(\n",
        "    ResLayer(\n",
        "        config,\n",
        "        3,\n",
        "        16,\n",
        "        32,\n",
        "        (3,3)\n",
        "    ),\n",
        "    Pool(\n",
        "        config,\n",
        "        kernel_shape=(2,2),\n",
        "        stride=2\n",
        "    ),\n",
        "    DictReLU(),\n",
        "    ResLayer(\n",
        "        config,\n",
        "        32,\n",
        "        64,\n",
        "        128,\n",
        "        (3,3)\n",
        "    ),\n",
        "    Pool(\n",
        "        config,\n",
        "        sequence_dim_num=2\n",
        "    ),\n",
        "    LayerNorm(\n",
        "        config,\n",
        "        128\n",
        "    ),\n",
        "    Dropout(config),\n",
        "    Linear(\n",
        "        config,\n",
        "        128,\n",
        "        128,\n",
        "        init_multiplier=2 ** .5\n",
        "    ),\n",
        "    DictReLU(),\n",
        "    LayerNorm(\n",
        "        config,\n",
        "        128\n",
        "    ),\n",
        "    Dropout(config),\n",
        "    Linear(\n",
        "        config,\n",
        "        128,\n",
        "        10\n",
        "    )\n",
        ")\n",
        "\n",
        "optimizer = AdamW(model.parameters())\n",
        "\n",
        "dataset_train = {\n",
        "    \"features\": train_features,\n",
        "    \"label\": train_labels\n",
        "}\n",
        "dataset_valid = {\n",
        "    \"features\": valid_features,\n",
        "    \"label\": valid_labels\n",
        "}\n",
        "\n",
        "log = train_supervised(\n",
        "    config,\n",
        "    dataset_train,\n",
        "    dataset_valid,\n",
        "    get_cross_entropy,\n",
        "    get_accuracy,\n",
        "    model,\n",
        "    optimizer,\n",
        "    target_key=\"label\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}